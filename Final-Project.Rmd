```{r hw2_setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=TRUE)
```

# Homework 2 {-}

## 1.
```{r}
# library statements 
# read in data
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(lubridate)
tidymodels_prefer()

accidents <- read_csv("accident_clean.csv")
```

```{r}
# how we cleaned the data

# filter(year(Start_Time) >= 2018, year(Start_Time) <= 2019) %>%
# drop_na(.) %>%
# select(-End_Time, -Airport_Code, -Timezone, -Weather_Timestamp, -Civil_Twilight, -Nautical_Twilight,-Astronomical_Twilight, -Traffic_Calming, -`Humidity(%)`, -`Wind_Chill(F)`, -Railway,  -Bump, -Amenity, -Country, -`Pressure(in)`, -Wind_Direction, -Give_Way, -No_Exit, -Roundabout, - Station, -Stop, -Turning_Loop, - Stop, -Description, - Street, -Severity) %>%
# sample_frac(size = 1/5) %>%
# mutate(Crossing = if_else(Crossing, 1, 0)) %>%
# mutate(Traffic_Signal = if_else(Traffic_Signal, 1, 0)) %>%
# mutate(logDist = log(`Distance(mi)`+.1)) %>%
# select(-`Distance(mi)`)
```

```{r}
# creation of cv folds
set.seed(253)

accident_cv <- vfold_cv(accidents, v = 10) # this is the random part

training(accident_cv$splits[[1]]) # pulls training data for the 1st split (1st fold is testing set)
testing(accident_cv$splits[[1]]) # pulls testing data for the 1st split (1st fold is testing set)
```

a. Use ordinary least squares (OLS) by using the `lm` engine and LASSO (`glmnet` engine) to build  a series of initial regression models for your quantitative outcome as a function of the predictors of interest. (As part of data cleaning, exclude any variables that you don't want to consider as predictors.)
  - You'll need two model specifications, `lm_spec` and `lm_lasso_spec` (you'll need to tune this one).
  
```{r}
# model specifications
lm_spec <-
    linear_reg() %>% 
    set_engine(engine = 'lm') %>% 
    set_mode('regression')

lm_lasso_spec <- 
    linear_reg() %>%
    set_args(mixture = 1, penalty = tune()) %>% 
    set_engine(engine = 'glmnet') %>%
    set_mode('regression')
```

b. For each set of variables, you'll need a `recipe` with the `formula`, `data`, and pre-processing steps
  - You may want to have steps in your recipe that remove variables with near zero variance (`step_nzv()`), remove variables that are highly correlated with other variables (`step_corr()`), normalize all quantitative predictors (`step_normalize(all_numeric_predictors())`) and add indicator variables for any categorical variables (`step_dummy(all_nominal_predictors())`).
  - These models should not include any transformations to deal with nonlinearity. You'll explore this in the next investigation.
        
```{r}
# recipes & workflows

car_rec <- recipe(logDist ~ `Side` + `Visibility(mi)` + `Temperature(F)` + `Wind_Speed(mph)` + `Precipitation(in)` + `Weather_Condition` + `Crossing` + `Junction` + `Traffic_Signal` + `Sunrise_Sunset`, data = accidents) %>%
    step_nzv(all_predictors()) %>%
    step_other(all_nominal_predictors()) %>% 
    step_normalize(all_numeric_predictors()) %>%
    step_dummy(all_nominal_predictors()) 

model_wf <- workflow() %>%
    add_recipe(car_rec) %>%
    add_model(lm_spec)

fit_model <- model_wf %>% fit(data = accidents)

car_rec %>% prep(accidents) %>% juice()

lasso_wf_car <- workflow() %>%
    add_recipe(car_rec) %>%
    add_model(lm_lasso_spec)
```


```{r}
#fit & tune models
mod1_cv <- fit_resamples(model_wf, 
                         resamples = accident_cv, 
                         metrics = metric_set(rmse, rsq, mae))

penalty_grid <- grid_regular(
  penalty(range = c(-3, 1)), #log10 transformed 
  levels = 30)

tune_output <- tune_grid( # new function for tuning parameters
  lasso_wf_car, # workflow
  resamples = accident_cv, # cv folds
  metrics = metric_set(rmse, mae),
  grid = penalty_grid # penalty grid defined above
)

best_se_penalty <- select_by_one_std_err(tune_output, metric = 'mae', desc(penalty))
best_se_penalty # choose penalty value based on the largest penalty within 1 se of the lowest CV MAE

best_penalty <- select_best(tune_output, metric = 'mae')
best_penalty # choose penalty value based on lowest mae

autoplot(tune_output) + theme_classic()

final_wf <- finalize_workflow(lasso_wf_car, best_penalty) # incorporates penalty value to workflow
final_wf_se <- finalize_workflow(lasso_wf_car, best_se_penalty)

final_fit <- fit(final_wf, data = accidents)
final_fit_se <- fit(final_wf_se, data = accidents)

tidy(final_fit)
tidy(final_fit_se)
```

c. Estimate the test performance of the models using CV. Report and interpret (with units) the CV metric estimates along with a measure of uncertainty in the estimate (`std_error` is readily available when you used `collect_metrics(summarize=TRUE)`).
  - Compare estimated test performance across the models. Which models(s) might you prefer?

```{r}
#  calculate/collect CV metrics
mod1_cv %>% collect_metrics()
```

d. Use residual plots to evaluate whether some quantitative predictors might be better modeled with nonlinear relationships.

```{r}
# visual residuals

#how do we do this?
mod1_output <- fit_model %>% 
    predict(new_data = accidents) %>% #this function maintains the row order of the new_data
    bind_cols(accidents) %>%
    mutate(resid = logDist - .pred)


mod1_output %>% 
  #augment() %>%
  ggplot(aes(x = .pred, y = resid)) + #note patterns in residual/error
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0) +
  theme_classic()

mod1_output %>% 
  #augment() %>%
  ggplot(aes(x = `Temperature(F)`, y = resid)) + #note patterns in residual/error
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0) +
  theme_classic()
```

e. Which variables do you think are the most important predictors of your quantitative outcome? Justify your answer. Do the methods you've applied reach consensus on which variables are most important? What insights are expected? Surprising?
  - Note that if some (but not all) of the indicator terms for a categorical predictor are selected in the final models, the whole predictor should be treated as selected.

<br>

## 2. 
**Summarize investigations**
    - Decide on an overall best model based on your investigations so far. To do this, make clear your analysis goals. Predictive accuracy? Interpretability? A combination of both?



<br>

## 3. 
**Societal impact**
Are there any harms that may come from your analyses and/or how the data were collected?

One element of the way data was collected that may be harmful is the fact that this information is collected from API’s from Mapquest and Bing which would be tracking live traffic. A lot of the time, this traffic is collected from users of the apps which many times do not realize they have consented to allowing their location information to be collected. As a result, information on traffic duration is made up of individuals who may not want to contribute to the research. Similarly, another harm of the dataset could be the possible inclusion of multiples when recording the accidents. The data collectors took measures to filter out any duplicates, but there is a possibility that there are still some left in that could affect the integrity of our results. 

What cautions do you want to keep in mind when communicating your work?

We want to make note that since the dataset is so extensive ( >1M cases), we needed to filter the dataset down to almost half of the original amount in order to be able to run our models. As a result, we are only looking at specific years, which may be reflective of whatever the conditions of overall traffic patterns are. For example, by excluding 2020, we are not measuring the effect COVID-19 had on traffic. Likewise, not incorporating 2016 and 2017 will not take into account the lower gas prices that may have led to higher traffic volumes. As a result, we need to take these and other possible shortcomings of the dataset into consideration.

# Homework 3 {-}

## 2.
**Accounting for nonlinearity**
a. Update your OLS model(s) and LASSO model to use natural splines for the quantitative predictors.
  -You’ll need to update the recipe to include step_ns() for each quantitative predictor.
  -It’s recommended to use few knots (e.g., 2 knots = 3 degrees of freedom).
  
```{r}
spline_rec <- recipe(logDist ~ ., data = accidents) %>% #How to remove only one predictor
  step_dummy(all_nominal_predictors()) %>%
  step_rm(`Weather_Condition_Partly.Cloudy`)
  #step_ns(Terminal, deg_free = 3) %>%
  #step_ns(Expend, deg_free = 3) #ask Brianna about what we need

# Check the pre-processed data
spline_rec %>% prep(accidents) %>% juice() #why did ID show up? How to analyze? How do we know which ones to do stepns for?
#How do we know which predictors are the most relevant?
```

```{r}
lm_spec <-
  linear_reg() %>%
  set_engine(engine = 'lm') %>%
  set_mode('regression')

# Workflow (Recipe + Model)
spline_wf <- workflow() %>% 
  add_recipe(spline_rec) %>%
  add_model(lm_spec) 


# CV to Evaluate
cv_output <- fit_resamples( 
  spline_wf, # workflow
  resamples =accident_cv, # cv folds
  metrics = metric_set(mae)
)
cv_output %>% collect_metrics()

# Fit model
ns_mod <- spline_wf %>%
  fit(data = accidents) 

ns_mod %>%
  tidy()
```


b. Compare insights from variable importance analyses here and the corresponding results from the Investigation 1. Now after having accounted for nonlinearity, have the most relevant predictors changed? 
  -Note that if some (but not all) of the spline terms are selected in the final models, the whole predictor should be treated as selected.
c. Fit a GAM using spline terms using the set of variables deemed to be most relevant based on your investigations so far.
  -How does test performance of the GAM compare to other models you explored?
  -Do you gain any insights from the GAM output plots for each predictor?
d. Don’t worry about KNN for now.


3. Summarize investigations
  -Decide on an overall best model based on your investigations so far. To do this, make clear your analysis goals. Predictive accuracy? Interpretability? A combination of both?


4. Societal impact
  -Are there any harms that may come from your analyses and/or how the data were collected?
  -What cautions do you want to keep in mind when communicating your work?





















